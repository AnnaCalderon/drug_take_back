---
title: "Webscraping Drug Takeback"
# subtitle: ""
# author: Kyle Grealis
description: "in New York"
format: 
  html:
    page-layout: full
    grid: 
      margin-width: 0px
    toc: true
    toc-title: ""
    toc-location: left
    self-contained: true
    css: styles.css
    theme: sandstone
    code-tools: true
    code-copy: true
execute: 
  echo: false
  warning: false
  cache: true
# server: shiny
--- 

```{r}
#| label: setup
library(conflicted)
conflict_prefer('filter', 'dplyr')
library(janitor)
library(polite)
library(rvest)
library(stringr)
library(tidyverse)
library(tidycensus)
library(tidygeocoder)
library(sf)
library(mapview)
library(xml2)
```

# Data importing and cleaning


```{r}
# set-up for web scraping:
# base_url <- 
#   'https://medtakebacknewyork.org/?cpage=%s&zipcode=10128'

# counter:
# i <- 1

# table that will be created:
# new_york_raw <- tibble()
```


```{r}

# create a while loop that iterates through all of the pages on the main website:
# while (i <= 113) {
# 
#   new_page <-
#     read_html(
#       # change the page number with each iteration of the loop
#       sprintf(
#         base_url,
#         i
#       )
#     )
# 
#   new_table <-
#     tibble(
# 
#       # This will extract particular elements from the webpage. Using regex,
#       # it will then obtain certain elements for each site: name, location, etc.
#       facility =
#         new_page|>
#         html_elements('.company') |>
#         html_element('b') |>
#         html_text2(),
# 
#       zip_code =
#         new_page|>
#         html_elements('.address') |>
#         html_text2() |>
#         str_remove(pattern = '\\nGet Directions') |>
#         str_sub(start = -5),
# 
#       city =
#         new_page|>
#         html_elements('.address') |>
#         html_text2() |>
#         str_extract('(?<=\\n)(.*?)(?=,)') |>
#         str_to_title(),
# 
#       street =
#         new_page|>
#         html_elements('.address') |>
#         html_text2() |>
#         str_extract(pattern = '(.*?)\\n') |>
#         str_remove(pattern = '\\n') |>
#         str_to_title()
# 
#     )
# 
#   # append each iteration of the data to the main table:
#   new_york_raw <-
#     rbind(
#       new_york_raw,
#       new_table
#     )
# 
#   # increase counter
#   i <- i + 1
# 
# }
```

```{r}
# save/import data
# rio::export(new_york_raw, 'data/ny_takeback_raw.rda')
doh_data_raw <- rio::import('data/ny_takeback_raw.rda')
```

```{r}
doh <- 
  doh_data_raw |> 
  
  # modify variables...
  mutate(
    
    source = 'doh',
    
    # create all lowercase character variables
    across(where(is.character), str_to_lower),
    
    # remove all . from street address (i.e., both for E. and St.)
    street = str_remove_all(street, '\\.'),
    
    # clean the street address
    address = case_when(
      
      # use this website for more help: https://regex101.com
      # preceded by a space: \\s
      # only if at the end of a line: $
      # any type of punctuation: [[:punct:]]
      str_detect(street, '\\s([sS]t)([[:punct:]].|\\s|$)') ~ 
        str_replace(street, '\\s([sS]t)', ' street'),
      
      str_detect(street, '\\s([rR]d)([[:punct:]]|\\s|$)') ~
        str_replace(street, '\\s([rR]d)', ' road'),
      
      str_detect(street, '\\s([dD]r)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([dD]r)', ' drive'),
      
      str_detect(street, '\\s([aA]ve)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([aA]ve)', ' avenue'),

      str_detect(street, '\\s([bB]lvd)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([bB]lvd)', ' boulevard'),

      str_detect(street, '\\s([pP]lace)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([pP]lace)', ' place'),
      
      str_detect(street, '\\s([hH]wy)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([hH]wy)', ' highway'),
      
      TRUE ~ street
    ),
    
    state = 'ny'
  ) |>  
  
  # reduce the number of variables
  select(
    source, facility, address, city, state, zip_code
  ) 
```

```{r}
head(doh)
```


```{r}
# import raw csv of DEA data
dea_data_raw <-
  rio::import('data/dea_data_raw.csv')
```


```{r}
dea_first_clean <-
  dea_data_raw |> 
  
  # better names for coding
  clean_names() |> 
  
  # if addr_1 doesn't have numeric street address, use address in addr_2
  mutate(
    addr_1 = ifelse(str_starts(addr_1, "[0-9]+"), addr_1, addr_2)
  ) |> 
  
  filter(
    # include NY only
    str_detect(city_state_zip, "NY"),
    # remove locations with missing street address
    addr_1 != ''
  ) # N=1406
```

```{r}
dea <- 
  dea_first_clean |> 

  # create consistent variable names across datasets
  rename(
    facility = bus_name,
    street = addr_1) |> 
  
  # modify variables...
  mutate(
    
    source = 'dea',
    
    # create all lowercase character variables
    across(where(is.character), str_to_lower),
    
    # remove all . from street address (i.e., both for E. and St.)
    street = str_remove_all(street, '\\.'),
    
    # clean the street address
    address = case_when(
      
      # use this website for more help: https://regex101.com
      # preceded by a space: \\s
      # only if at the end of a line: $
      # any type of punctuation: [[:punct:]]
      str_detect(street, '\\s([sS]t)([[:punct:]].|\\s|$)') ~ 
        str_replace(street, '\\s([sS]t)', ' street'),
      
      str_detect(street, '\\s([rR]d)([[:punct:]]|\\s|$)') ~
        str_replace(street, '\\s([rR]d)', ' road'),
      
      str_detect(street, '\\s([dD]r)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([dD]r)', ' drive'),
      
      str_detect(street, '\\s([aA]ve)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([aA]ve)', ' avenue'),

      str_detect(street, '\\s([bB]lvd)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([bB]lvd)', ' boulevard'),

      str_detect(street, '\\s([pP]lace)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([pP]lace)', ' place'),
      
      str_detect(street, '\\s([hH]wy)([[:punct:]]|\\s|$)') ~ 
        str_replace(street, '\\s([hH]wy)', ' highway'),
      
      TRUE ~ street
    ),
    
    # split the original variable to assess for repeat locations...
    # ^ is the anchor for the beggining of the string until the first comma
    city = str_extract(city_state_zip, '^(.*?)(?=,)'),
    state = str_extract(city_state_zip, '(?<=,\\s)(\\w+)\\s'),
    zip_code = str_extract(city_state_zip, '[0-9]+')
  ) |> 
  
  # keep only new york
  # filter(state == 'ny') |>
  
  # reduce the number of variables
  select(
    source, facility, address, city, state, zip_code
  )
```

```{r}
dea |> 
  dplyr::filter(state == 'ny')
# head(dea)
```

```{r}
#| message: false
# combine datasets
new_york_all_locations <-
  dea |> 
  full_join(doh, keep = FALSE) # N=3785
```

```{r}
# remove repeat addresses

# step 1: visualize repeats...
new_york_all_locations |> 
  count(address, zip_code) |> 
  arrange(desc(n)) |> 
  filter(n > 1)

# step 2: keep one instance of address
new_york <-
  new_york_all_locations |> 
  # keep only unique street/zip code locations and all other variables
  distinct(address, zip_code, .keep_all = TRUE)
```

```{r}
# final dataset has how many distinct address locations?
new_york |> 
  nrow()
```

```{r}
# create address variable needed for `tidygeocoder` functions
new_york <-
  new_york |> 
  mutate(
    address_original = glue::glue('{address}, {city}, {state} {zip_code}')
  )
```



# Use `tidygeocoder` to find county

```{r}
# start_time <- proc.time()
# 
# ny_geocode <-
#   new_york |> 
#   
#   # obtain latitude and longitude
#   tidygeocoder::geocode(
#     address = address_original,
#     method = 'arcgis'
#   ) |> 
#   
#   # reverse pass info to get full address with county name
#   tidygeocoder::reverse_geocode(
#     lat = lat,
#     long = long,
#     method = 'osm'
#   ) |> 
#   clean_names() |> 
#   rename(
#     geo_address = address_10
#   )
# 
# stop_time <- proc.time()
```

```{r}
# stop_time - start_time
```


```{r}
# rio::export(ny_geocode, 'data/ny_geocode.RData')
ny_geocode <- 
  rio::import('data/ny_geocode.RData') |> 
  rename(
    address = address_3
  )

head(ny_geocode)
```


```{r}
# determine which locations were able to obtain county info from geocoder
has_county <- 
  ny_geocode |> 
  mutate(
    county_error = if_else(
      !str_detect(str_to_lower(geo_address), 'county'), 1, 0
    )
  ) |> 
  filter(county_error == 0) |> 
  select(-county_error)
    
# create dataset that needs county info
needs_county <- 
  ny_geocode |> 
  mutate(
    county_error = if_else(
      !str_detect(str_to_lower(geo_address), 'county'), 1, 0
    )
  ) |> 
  filter(county_error == 1) |> 
  select(-county_error)
```

```{r}
county_info <-
  has_county |> 
  # regex: (?<=,\\s) == look ahead for a comma followed by a space
  # regex: \\w+ select word(s) that are...
  # regex: (?= County) followed by, but not including the word, County
  mutate(county = str_extract(geo_address, '(?<=,\\s)\\w+(?= County)')) |> 
  select(
    -c(address_original, lat, long, geo_address)
  )
```

```{r}
## NOTE: needs_county subset still needs to be completed. it is the NYC boroughs
## and need to determine if they are included in the takeback program

# found_county <-
#   needs_county |> 
#   SOME MAGIC DONE HERE TO GET THIS INFO

# ny_county_data <-
#   found_county |> 
#   full_join(has_county)
```

```{r}
# filter county_info dataset to only included necessary counties

necessary_counties <- c(
  'Broome', 'Cayuga', 'Chautauqua', 'Columbia', 'Cortland', 'Genesee',
  'Greene', 'Lewis', 'Orange', 'Putnam', 'Sullivan', 'Ulster', 'Yates'
)

# ny_county_data |>     ### UNCOMMENT once all county data found and merged!!
county_info |>          ### DELETE this line once the line above has been done!!
  filter(
    (county %in% necessary_counties) |
      (county == 'Erie' & str_to_title(city) == 'Buffalo') |
      (county == 'Monroe' & str_to_title(city) == 'Rochester') |
      (county == 'Suffolk' & str_to_title(city) == 'Brookhaven')
  ) |> 
  group_by(county) |> 
  summarize(
    counts = n()
  ) |> 
  ungroup() |> 
  mutate(percent = round(counts/sum(counts)*100, 2))
```

```{r}
# county_info |> 
#   filter(county == 'Erie') |> 
#   View()
```



```{r}
# end
```

